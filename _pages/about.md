---
layout: about
title: about
permalink: /

profile:
  align: right
  image: avatar2.jpg
  image_cicular: false # crops the image to make it circular
  address: >
    <p>Photo was taken at qing-tian-gang (擎天崗)</p>
    <p>Taipei, Taiwan, Jan. 2021</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am a second-year master's student at UW, supervised by Prof. [Shane Steinert-Threlkeld](https://www.shane.st/).

Before UW, I was a research assistant supervised by Prof. [Wang, Hsin-Min](https://homepage.iis.sinica.edu.tw/pages/whm/index_en.html) and Prof. [Ko, Ming-Tat](https://homepage.iis.sinica.edu.tw/pages/mtko/index_en.html) in [SLAM Laboratory](http://slam.iis.sinica.edu.tw) at the Institue of Information Science, Academia Sinica. I received a B.S. in Computer Science and Information Engineering from [National Taipei University of Technology (Taipei Tech)](https://www-en.ntut.edu.tw) in June 2021.

Prior to that, I was a data engineer intern at [LINE Taiwan](https://linecorp.com/en/), I develop NLP tools to solve real-world problems. Before I pivoted to the field of NLP, I was a software developer intern in [iCook](https://icook.tw) and [Glossika](https://ai.glossika.com) where I learned the foundations of software development.

My research interests are speech and natural language processing (SLP). Specifically, I am interested in the following topics:

(a) make language technologies accessible: can we design model architectures that are less data-hungry and computing efficient?

(b) multi-modal language technologies: as human communications involves a lot of different modalities, can we design model architectures that are more capable of multi-modal interactions?

(c) understanding model behaviors: I believe the most efficient way to improve current language technologies is by understanding the models' behavior and limitations. By analyzing model behavior, we can better design model architectures that are less data-hungry and computing efficient.

